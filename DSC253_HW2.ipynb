{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ_ItWyd94zf",
        "outputId": "861a96dd-22bc-4e5f-da52-0a004f53557f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AutoPhrase'...\n",
            "remote: Enumerating objects: 967, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 967 (delta 66), reused 122 (delta 60), pack-reused 830 (from 1)\u001b[K\n",
            "Receiving objects: 100% (967/967), 199.80 MiB | 10.12 MiB/s, done.\n",
            "Resolving deltas: 100% (438/438), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shangjingbo1226/AutoPhrase.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd AutoPhrase/ && ./auto_phrase.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBerxT4AACBo",
        "outputId": "f8f18610-0752-4741-9b12-67d4cb022537"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Compilation===\u001b[m\n",
            "mkdir -p bin\n",
            "g++ -std=c++11 -Wall -O3 -msse2  -fopenmp  -I.. -pthread -lm -Wno-unused-result -Wno-sign-compare -Wno-unused-variable -Wno-parentheses -Wno-format -o bin/segphrase_train src/main.cpp\n",
            "g++ -std=c++11 -Wall -O3 -msse2  -fopenmp  -I.. -pthread -lm -Wno-unused-result -Wno-sign-compare -Wno-unused-variable -Wno-parentheses -Wno-format -o bin/segphrase_segment src/segment.cpp\n",
            "\u001b[32m===Downloading Toy Dataset===\u001b[m\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  198M  100  198M    0     0  14.3M      0  0:00:13  0:00:13 --:--:-- 8464k\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t4m15.512s\n",
            "user\t7m3.564s\n",
            "sys\t0m16.609s\n",
            "Detected Language: EN\u001b[0K\n",
            "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
            "No provided expert labels.\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3253k  100 3253k    0     0  1759k      0  0:00:01  0:00:01 --:--:-- 1758k\n",
            "english parameter file (Linux, UTF8) installed.\n",
            "\n",
            "\u001b[32m===AutoPhrasing===\u001b[m\n",
            "=== Current Settings ===\n",
            "Iterations = 2\n",
            "Minimum Support Threshold = 10\n",
            "Maximum Length Threshold = 6\n",
            "POS-Tagging Mode Enabled\n",
            "Number of threads = 10\n",
            "Labeling Method = DPDN\n",
            "\tAuto labels from knowledge bases\n",
            "\tMax Positive Samples = -1\n",
            "=======\n",
            "Loading data...\n",
            "# of total tokens = 111149629\n",
            "max word token id = 553924\n",
            "# of documents = 5547032\n",
            "# of distinct POS tags = 57\n",
            "Mining frequent phrases...\n",
            "selected MAGIC = 553933\n",
            "# of frequent phrases = 1801956\n",
            "Extracting features...\n",
            "Constructing label pools...\n",
            "\tThe size of the positive pool = 32635\n",
            "\tThe size of the negative pool = 1762859\n",
            "# truth patterns = 201855\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Rectifying features...\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Dumping results...\n",
            "Done.\n",
            "\n",
            "real\t26m38.014s\n",
            "user\t42m58.123s\n",
            "sys\t2m35.069s\n",
            "\u001b[32m===Saving Model and Results===\u001b[m\n",
            "\u001b[32m===Generating Output===\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd AutoPhrase/ && ./phrasal_segmentation.sh"
      ],
      "metadata": {
        "id": "n4b4VSAmW8DN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2f44c8-7156-46fe-c653-42b171b4b38d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Compilation===\u001b[m\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t0m2.603s\n",
            "user\t0m4.425s\n",
            "sys\t0m0.309s\n",
            "Detected Language: EN\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "Current step: Merging...\u001b[0K\n",
            "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
            "=== Current Settings ===\n",
            "Segmentation Model Path = models/DBLP/segmentation.model\n",
            "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
            "\tQ(multi-word phrases) >= 0.500000\n",
            "\tQ(single-word phrases) >= 0.800000\n",
            "=======\n",
            "POS guided model loaded.\n",
            "# of loaded patterns = 723100\n",
            "# of loaded truth patterns = 234490\n",
            "POS transition matrix loaded\n",
            "Phrasal segmentation finished.\n",
            "   # of total highlighted quality phrases = 26460\n",
            "   # of total processed sentences = 13830\n",
            "   avg highlights per sentence = 1.91323\n",
            "\n",
            "real\t0m2.041s\n",
            "user\t0m1.837s\n",
            "sys\t0m0.185s\n",
            "\u001b[32m===Generating Output===\u001b[m\n",
            "\n",
            "real\t0m2.356s\n",
            "user\t0m2.777s\n",
            "sys\t0m0.214s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did you find any phrases with abnormal scores (e.g. non-phrase with a high score or good phrase with a low score)? Do they show a systematic pattern? What can be the possible reason behind it and how to improve the algorithm to avoid such mistakes**\n",
        "\n",
        "Some phrases have abnormal scores, like the non-phrase \"cs1 cs2\" with a high score of 0.97 and the meaningful phrase \"surge in\" with a low score of 0.10. This likely happens because the model is trained on generalized data, not tuned for specific phrases. To improve, we could fine-tune on domain-specific data, add syntax-based features to detect non-phrases, and use semantic similarity to better assess phrase quality."
      ],
      "metadata": {
        "id": "X6HfAszPWRGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Read the segmented corpus file\n",
        "with open('segmented_corpus.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Convert each phrase into a single token\n",
        "def convert_phrases_to_tokens(lines):\n",
        "    tokenized_lines = []\n",
        "    for line in lines:\n",
        "        # Use regex to find phrases within <phrase>...</phrase> tags\n",
        "        tokenized_line = re.sub(r'<phrase_Q=[^>]+>([^<]+)</phrase>', lambda m: '_'.join(m.group(1).split()), line)\n",
        "        tokenized_lines.append(tokenized_line)\n",
        "    return tokenized_lines\n",
        "\n",
        "# Save the modified corpus with single tokens\n",
        "tokenized_corpus = convert_phrases_to_tokens(lines)\n",
        "with open('tokenized_corpus.txt', 'w') as file:\n",
        "    for line in tokenized_corpus:\n",
        "        file.write(line)"
      ],
      "metadata": {
        "id": "oMiIpXziXzwi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Tokenize the tokenized corpus into sentences for Word2Vec\n",
        "sentences = [line.strip().split() for line in tokenized_corpus]\n",
        "\n",
        "# Train Word2Vec model on the tokenized corpus\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
        "w2v_model.save(\"phrase_embeddings.model\")"
      ],
      "metadata": {
        "id": "S-O451jNX1bT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "\n",
        "# Retrieve the phrase embeddings\n",
        "phrases = list(w2v_model.wv.index_to_key)\n",
        "embeddings = np.array([w2v_model.wv[phrase] for phrase in phrases])\n",
        "\n",
        "# KMeans clustering\n",
        "kmeans = KMeans(n_clusters=6, random_state=0).fit(embeddings)\n",
        "kmeans_labels = kmeans.labels_\n",
        "\n",
        "# GMM clustering\n",
        "gmm = GaussianMixture(n_components=6, random_state=0).fit(embeddings)\n",
        "gmm_labels = gmm.predict(embeddings)\n",
        "\n",
        "# Output clusters (20 phrases from each cluster)\n",
        "for i in range(6):\n",
        "    kmeans_cluster_phrases = [phrases[j] for j in range(len(phrases)) if kmeans_labels[j] == i][:20]\n",
        "    gmm_cluster_phrases = [phrases[j] for j in range(len(phrases)) if gmm_labels[j] == i][:20]\n",
        "    print(f\"\\nKMeans Cluster {i+1}:\", kmeans_cluster_phrases)\n",
        "    print(f\"\\nGMM Cluster {i+1}:\", gmm_cluster_phrases)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x5VxpENYGqH",
        "outputId": "b91c2023-0cd8-4014-c04e-f4eae03518b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KMeans Cluster 1: ['Algorithms.', 'Techniques.', 'Specification', 'Introduction.', 'Concurrency_Control', 'Internet.', 'Computing', 'deal', 'Artificial_Intelligence', 'Web.', 'Logic_Programming', 'Complexity', 'Use', 'UML.', 'Datenbanksysteme', 'Basic', 'Mining', 'Languages.', 'Visualization', 'Recovery']\n",
            "\n",
            "GMM Cluster 1: ['Approach.', 'Architecture', 'Algorithms.', 'Techniques.', 'Specification', 'Generation', 'Introduction.', 'Concurrency_Control', 'demonstrated', 'defined', 'Computing', 'deal', 'Artificial_Intelligence', 'Industrial', 'Web.', 'Logic_Programming', 'Mapping', 'Complexity', 'Use', 'time,']\n",
            "\n",
            "KMeans Cluster 2: ['-', 'Using', 'used', 'paper', 'use', 'present', 'approach', 'Database', 'their', 'models', 'how', 'problem', 'An', 'one', '3-D', 'book', 'set', 'surface', 'well', 'other']\n",
            "\n",
            "GMM Cluster 2: ['-', 'Using', 'used', 'paper', 'use', 'present', 'approach', 'Database', 'their', 'models', 'how', 'problem', 'An', 'one', '3-D', 'book', 'set', 'surface', 'well', 'other']\n",
            "\n",
            "KMeans Cluster 3: ['für', 'Technology', 'Data_Mining.', 'IT', 'Application', 'An_Introduction', 'von', 'introduced', 'Models.', 'Online', 'Fast', 'solution', 'Issues', 'Robust', 'Query_Processing', 'Modeling.', 'taken', '2.', 'Method', 'Computer']\n",
            "\n",
            "GMM Cluster 3: ['für', 'Technology', 'Data_Mining.', 'IT', 'Application', 'An_Introduction', 'von', 'introduced', 'Models.', 'Online', 'Fast', 'solution', 'Issues', 'Robust', 'Query_Processing', 'Modeling.', 'taken', '2.', 'Method', 'Computer']\n",
            "\n",
            "KMeans Cluster 4: ['the', 'of', 'and', 'a', 'to', 'in', 'for', 'is', 'The', 'on', 'with', 'are', '3D', 'from', 'that', 'by', 'as', 'A', 'an', 'this']\n",
            "\n",
            "GMM Cluster 4: ['the', 'of', 'and', 'a', 'to', 'in', 'for', 'is', 'The', 'on', 'with', 'are', '3D', 'from', 'that', 'by', 'as', 'A', 'an', 'this']\n",
            "\n",
            "KMeans Cluster 5: ['Databases.', 'System.', 'Data_Mining', 'Applications', 'Multimedia', 'Introduction', 'Algorithms', 'Images.', 'Advanced', 'Reconstruction', 'Programming', 'Active', 'analysis', 'Applications.', 'Automatic', 'Logic', 'New', 'Implementation', 'UML', 'Discovery']\n",
            "\n",
            "GMM Cluster 5: ['Databases.', 'System.', 'Data_Mining', 'Applications', 'Multimedia', 'Introduction', 'Algorithms', 'Images.', 'Advanced', 'Reconstruction', 'Programming', 'Active', 'analysis', 'Applications.', 'Automatic', 'Logic', 'New', 'Implementation', 'UML', 'Discovery']\n",
            "\n",
            "KMeans Cluster 6: ['und', 'System', 'Information', 'Modeling', 'Systems.', 'Data', 'object', 'Design', 'Object-Oriented', 'Systems', 'Approach', 'number', 'order', 'presents', 'paper,', 'Knowledge', 'Java', 'modeling', 'Models', 'technique']\n",
            "\n",
            "GMM Cluster 6: ['und', 'System', 'Information', 'Modeling', 'Systems.', 'Data', 'object', 'Design', 'Object-Oriented', 'Systems', 'Approach', 'number', 'order', 'presents', 'paper,', 'Knowledge', 'Java', 'modeling', 'Models', 'technique']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Names of Clusters**\n",
        "\n",
        "Cluster 1 : Topics in Computer Science\n",
        "\n",
        "Cluster 2: Misc\n",
        "\n",
        "Cluster 3: Terms in Information Technology\n",
        "\n",
        "Cluster 4: Preposition and articles\n",
        "\n",
        "Cluster 5: Database related terms\n",
        "\n",
        "Cluster 6: System related terms\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pKE30P7VZs-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "GMM can capture more nuanced clusters since it considers that phrases may belong partially to multiple topics (e.g., \"Generation,\" \"Mapping,\" and \"time\" in Cluster 1 for GMM add interpretative depth).\n",
        "KMeans, on the other hand, results in more distinct separation, sometimes leading to terms that may feel out of context within the hard boundaries (e.g., \"deal\" in KMeans Cluster 1).\n",
        "KMeans assigns each data point strictly to one cluster, giving harder boundaries between clusters.\n",
        "GMM (Gaussian Mixture Model) allows for probabilistic cluster membership, so phrases can have some likelihood of belonging to multiple clusters, which can lead to more overlap in terms. For instance, in Cluster 1, GMM includes terms like \"demonstrated,\" \"defined,\" and \"Industrial,\" which have a slightly broader scope compared to KMeans.\n",
        "\n"
      ],
      "metadata": {
        "id": "V82O76LAZbeY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ap20WR30YHbc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}